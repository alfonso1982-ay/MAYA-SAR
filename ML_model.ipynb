{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrFo1hpyZU6FS6RNbMBRaE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aujFBRvsduJq","outputId":"b2241e29-498a-443a-b677-f8dd2229b5b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 93 rasters across baseline + hotspots (first 5):\n","[{'aoi': 1, 'year': 2020, 'quart': 'Q1', 'path': 'CLEAN/Interest_clean/AOI_1_2020_Q1.tif', 'source': 'hotspot'}, {'aoi': 1, 'year': 2020, 'quart': 'Q2', 'path': 'CLEAN/Interest_clean/AOI_1_2020_Q2.tif', 'source': 'hotspot'}, {'aoi': 1, 'year': 2020, 'quart': 'Q3', 'path': 'CLEAN/Interest_clean/AOI_1_2020_Q3.tif', 'source': 'hotspot'}, {'aoi': 1, 'year': 2020, 'quart': 'Q4', 'path': 'CLEAN/Interest_clean/AOI_1_2020_Q4.tif', 'source': 'hotspot'}, {'aoi': 1, 'year': 2021, 'quart': 'Q1', 'path': 'CLEAN/Interest_clean/AOI_1_2021_Q1.tif', 'source': 'hotspot'}]\n","Computing metrics per raster...\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2020_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2020_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2020_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2020_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2021_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2021_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2021_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2021_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2022_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2022_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2022_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2022_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2023_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2023_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2023_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2023_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2024_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2024_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2024_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2024_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2025_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2025_Q2.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2025_Q3.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_1_2025_Q4.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_2_2020_Q1.tif\n","â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for AOI_2_2020_Q2.tif\n"]}],"source":["# ============================================================\n","# 0) Setup\n","# ============================================================\n","!pip install -q rasterio google-cloud-storage imageio torch torchvision requests\n","\n","import os, re, csv, io, time, json\n","import numpy as np\n","import rasterio\n","import matplotlib.pyplot as plt\n","import imageio.v2 as imageio\n","from google.colab import auth\n","from google.cloud import storage\n","from collections import defaultdict\n","from datetime import datetime\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from rasterio.enums import Resampling\n","import shutil # Import shutil for file operations\n","import requests # Import requests\n","from io import BytesIO # Import BytesIO\n","\n","\n","# Authenticate in your Colab notebook\n","from google.colab import auth\n","auth.authenticate_user(clear_output=True)\n","\n","# âœ… Force ADC and environment variables for GDAL/Rasterio\n","import os\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/.config/application_default_credentials.json\"\n","os.environ[\"CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE\"] = \"/content/.config/application_default_credentials.json\"\n","os.environ[\"GS_OAUTH2_TOKEN\"] = \"ya29.fake\"  # bypass internal GDAL auth check\n","os.environ[\"CPL_VSIL_CURL_ALLOWED_EXTENSIONS\"] = \".tif\"\n","os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n","os.environ[\"GS_REQUESTER_PAYS\"] = \"YES\"  # optional for project-billed buckets\n","os.environ[\"GS_NO_SIGN_REQUEST\"] = \"NO\"\n","\n","\n","# Run this command to make all files in your bucket readable by anyone:\n","# !gsutil iam ch allUsers:objectViewer gs://nasa_sar_spacetron # Not needed with authenticated access\n","\n","# Confirm that it worked:\n","# !gsutil iam get gs://nasa_sar_spacetron # Not strictly needed for testing authenticated access\n","\n","\n","# This creates ADC at ~/.config/gcloud/application_default_credentials.json\n","# !gcloud auth application-default login -q # This is handled by auth.authenticate_user()\n","\n","# Set GOOGLE_APPLICATION_CREDENTIALS for GDAL/Rasterio\n","# Note: The path might be slightly different depending on the Colab environment,\n","# but this is a common location for ADC created by gcloud auth.\n","# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/root/.config/gcloud/application_default_credentials.json\" # Redundant with explicit path above\n","\n","\n","# ============================================================\n","# 1) Config (EDIT HERE IF NEEDED)\n","# ============================================================\n","PROJECT_ID        = \"nasa-space-apps-473722\"\n","BUCKET            = \"nasa_sar_spacetron\"\n","\n","MOSAICS_DIR       = \"CLEAN/SAR_Mosaics\"       # baseline mosaics\n","HOTSPOTS_DIR      = \"CLEAN/Interest_clean\"    # your hotspot/interest mosaics\n","\n","# Control window (for â€œnormal/baselineâ€ reference)\n","CONTROL_START     = (2018, \"Q1\")   # inclusive\n","CONTROL_END       = (2019, \"Q2\")   # inclusive\n","\n","ALL_YEARS         = list(range(2018, 2025))\n","QUARTS            = [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]\n","AOIS              = None  # None = all AOIs; or [1,2,3]\n","\n","# Choose the bands you want to use (best practice):\n","#   Option A (recommended): [\"VV_dB\",\"VH_dB\",\"angle\"]\n","#   Option B (if angle not available/consistent): [\"VV_dB\",\"VH_dB\",\"VV_minus_VH_dB\"]\n","SELECT_BANDS      = [\"VV_dB\",\"VH_dB\",\"angle\"]\n","\n","# Output Directories\n","# OUT_ROOT_GCS      = \"manifest/unified_timeseries\"  # stats, plots, gifs, anomaly csv\n","OUT_DRIVE_DIR     = \"/content/drive/MyDrive/SAR_Results\" # Output directory in Google Drive\n","MODEL_DIR_GCS     = \"models/trenmaya_unetae/v1_ae\" # saved model + metadata\n","\n","# Plots & GIFs\n","MAKE_PLOTS        = True\n","MAKE_GIFS         = True\n","GIF_DOWNSAMPLE    = 6            # downsample factor for GIF frames (keeps them small)\n","\n","# Thresholds (soft heuristics; adaptive fallback applied below)\n","WATER_VV_DB_THR   = -17.0        # typical water VV threshold (dB)\n","WATER_VH_DB_THR   = -22.0        # typical water VH threshold (dB)\n","BARE_DIFF_DB_THR  = 6.0          # VV-VH > 6 dB + VH low â‡’ bare/infrastructure\n","VH_LOW_DB_THR     = -15.0\n","\n","# ML hyperparams\n","PATCH_SIZE        = 256\n","BATCH_SIZE        = 8\n","EPOCHS_MAX        = 80\n","PATIENCE          = 12\n","LR                = 1e-3\n","USE_AMP           = True\n","BASE_CHANNELS     = 32\n","ANOM_PCTL         = 98    # percentile for \"interesting pixels\"\n","USE_STREAMING_PATCHES = True  # True = sample patches by windowed reads (memory-safe, slower)\n","\n","# Define IN_CHANNELS based on SELECT_BANDS\n","IN_CHANNELS = len(SELECT_BANDS)\n","\n","# ============================================================\n","# 2) GCS helpers & file parsing\n","# ============================================================\n","client = storage.Client(project=PROJECT_ID)\n","bucket_obj = client.bucket(BUCKET)\n","\n","def list_tifs(prefix):\n","    return [b.name for b in client.list_blobs(BUCKET, prefix=prefix) if b.name.endswith(\".tif\")]\n","\n","# Patterns like: AOI_1_2020_Q1.tif  / AOI 1 2020 Q1.tif\n","PAT = re.compile(r\".*AOI[_ ]?(\\d+)[_ ]?(\\d{4})[_ ]?Q([1-4])\\.tif$\", re.IGNORECASE)\n","def parse_info(path):\n","    m = PAT.match(os.path.basename(path))\n","    if not m: return None\n","    return dict(aoi=int(m.group(1)), year=int(m.group(2)), quart=f\"Q{m.group(3)}\", path=path)\n","\n","def list_items():\n","    items = []\n","    for src in (MOSAICS_DIR, HOTSPOTS_DIR):\n","        for p in list_tifs(src):\n","            meta = parse_info(p)\n","            if meta:\n","                meta[\"source\"] = \"hotspot\" if src == HOTSPOTS_DIR else \"baseline\"\n","                items.append(meta)\n","    if AOIS:\n","        items = [x for x in items if x[\"aoi\"] in AOIS]\n","    return sorted(items, key=lambda d:(d[\"aoi\"], d[\"year\"], d[\"quart\"], d[\"source\"]))\n","\n","items = list_items()\n","assert items, \"No mosaics found. Check folder names and file patterns.\"\n","print(f\"Found {len(items)} rasters across baseline + hotspots (first 5):\")\n","print(items[:5])\n","\n","# Useful dicts\n","orderQ = {\"Q1\":1, \"Q2\":2, \"Q3\":3, \"Q4\":4}\n","def t_index(y,q): return y*4 + orderQ[q]\n","def in_control(y,q):\n","    return t_index(*CONTROL_START) <= t_index(y,q) <= t_index(*CONTROL_END)\n","\n","# Replace your helper function:\n","def vsicurl_path(gcs_relpath):\n","    \"\"\"\n","    Return a public HTTPS link (no authentication) for rasterio to read.\n","    \"\"\"\n","    if gcs_relpath.startswith(\"gs://\"):\n","        parts = gcs_relpath.replace(\"gs://\", \"\").split(\"/\", 1)\n","        bucket, path = parts[0], parts[1]\n","    else:\n","        bucket, path = BUCKET, gcs_relpath\n","    return f\"/vsicurl/https://storage.googleapis.com/{bucket}/{path}\"\n","\n","\n","# ============================================================\n","# 3) Reading + band selection + basic proxies\n","# ============================================================\n","# Replace your read_selected_bands function:\n","def read_selected_bands(gcs_path, select_names=SELECT_BANDS):\n","    \"\"\"Read TIFF from GCS URL, using fallback mapping when band names are missing.\"\"\"\n","    try:\n","        # Build the HTTPS path\n","        if gcs_path.startswith(\"gs://\"):\n","            parts = gcs_path.replace(\"gs://\", \"\").split(\"/\", 1)\n","            bucket, path = parts[0], parts[1]\n","            http_url = f\"https://storage.googleapis.com/{bucket}/{path}\"\n","        elif gcs_path.startswith(\"CLEAN/\"):\n","            http_url = f\"https://storage.googleapis.com/{BUCKET}/{gcs_path}\"\n","        else:\n","            http_url = f\"https://storage.googleapis.com/{BUCKET}/{gcs_path}\"\n","\n","        # Download and open with rasterio\n","        response = requests.get(http_url, stream=True)\n","        response.raise_for_status()\n","        file_content = BytesIO(response.content)\n","\n","        with rasterio.open(file_content) as src:\n","            arr = src.read()\n","            prof = src.profile\n","            desc = list(src.descriptions or [])\n","            desc = [d if d else f\"B{i+1}\" for i, d in enumerate(desc)]\n","\n","        # --- Decide how to map bands ---\n","        n_bands = arr.shape[0]\n","        if not any(\"VV\" in d or \"VH\" in d for d in desc):\n","            # No names â†’ assume default mapping\n","            # (many Sentinel-1 mosaics follow: B1=VV, B2=VH, B3=angle)\n","            mapping = {\"VV_dB\": 0, \"VH_dB\": 1, \"angle\": 2}\n","            print(f\"â„¹ï¸ Using default band mapping (B1â†’VV, B2â†’VH, B3â†’angle) for {os.path.basename(http_url)}\")\n","        else:\n","            # Try to find matching names\n","            mapping = {}\n","            for name in select_names:\n","                found = [i for i, d in enumerate(desc) if name.lower() in d.lower()]\n","                if found:\n","                    mapping[name] = found[0]\n","                else:\n","                    mapping[name] = None\n","\n","        # --- Assemble selected array ---\n","        selected_arr = []\n","        for name in select_names:\n","            idx = mapping.get(name, None)\n","            if idx is None or idx >= n_bands:\n","                # Use zero-filled fallback if not found\n","                selected_arr.append(np.zeros_like(arr[0]))\n","            else:\n","                selected_arr.append(arr[idx])\n","\n","        selected_arr = np.stack(selected_arr, axis=0)\n","        return selected_arr.astype(\"float32\"), prof, desc\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"âŒ HTTP error downloading {gcs_path}: {e}\")\n","        return None, None, None\n","    except Exception as e:\n","        print(f\"âŒ Error reading {gcs_path}: {e}\")\n","        return None, None, None\n","\n","\n","# Replace your compute_proxies() function:\n","def compute_proxies(vv_db, vh_db):\n","    \"\"\"Compute SAR proxies (RVI, PR, water/bare fractions) robustly.\"\"\"\n","    # Replace NaNs and infs with sensible defaults\n","    vv_db = np.nan_to_num(vv_db, nan=-9999.0, posinf=-9999.0, neginf=-9999.0)\n","    vh_db = np.nan_to_num(vh_db, nan=-9999.0, posinf=-9999.0, neginf=-9999.0)\n","\n","    if np.all(vv_db == -9999.0) or np.all(vh_db == -9999.0):\n","        # No valid pixels at all\n","        return None, None, None, None\n","\n","    vv_lin = db_to_lin(vv_db)\n","    vh_lin = db_to_lin(vh_db)\n","\n","    # --- RVI and PR ---\n","    rvi = np.zeros_like(vv_lin)\n","    valid = (vv_lin + vh_lin) > 1e-6\n","    rvi[valid] = 4.0 * vh_lin[valid] / (vv_lin[valid] + vh_lin[valid])\n","    rvi = np.clip(rvi, 0, 1)\n","\n","    pr = np.zeros_like(vv_lin)\n","    valid = vv_lin > 1e-6\n","    pr[valid] = vh_lin[valid] / vv_lin[valid]\n","    pr = np.clip(pr, 0, 3)\n","\n","    # --- Water / Bare masks ---\n","    vv_thr = WATER_VV_DB_THR if np.isfinite(WATER_VV_DB_THR) else np.nanpercentile(vv_db, 7)\n","    vh_thr = WATER_VH_DB_THR if np.isfinite(WATER_VH_DB_THR) else np.nanpercentile(vh_db, 7)\n","    vv_thr = vv_thr if np.isfinite(vv_thr) else -20\n","    vh_thr = vh_thr if np.isfinite(vh_thr) else -25\n","\n","    water_mask = (vv_db <= vv_thr) & (vh_db <= vh_thr)\n","    diff_db = vv_db - vh_db\n","    bare_mask = (diff_db >= BARE_DIFF_DB_THR) & (vh_db <= VH_LOW_DB_THR)\n","\n","    metrics = {\n","        \"vv_db_mean\": float(np.nanmean(vv_db)),\n","        \"vh_db_mean\": float(np.nanmean(vh_db)),\n","        \"rvi_mean\": float(np.nanmean(rvi)),\n","        \"pr_mean\": float(np.nanmean(pr)),\n","        \"water_frac\": float(np.nanmean(water_mask)),\n","        \"bare_frac\": float(np.nanmean(bare_mask)),\n","    }\n","\n","    # Skip scenes with all NaNs or all zeros\n","    if not np.isfinite(metrics[\"rvi_mean\"]) or np.isnan(metrics[\"rvi_mean\"]):\n","        return None, None, None, None\n","\n","    return metrics, rvi, water_mask, bare_mask\n","\n","\n","\n","# ============================================================\n","# 4) Iterate images â†’ metrics per AOI/time; save CSV\n","# ============================================================\n","records = []\n","by_aoi_time = defaultdict(dict)   # (aoi, t_index) -> metrics\n","\n","print(\"Computing metrics per raster...\")\n","for it in items:\n","    try:\n","        arr, prof, desc = read_selected_bands(it[\"path\"], SELECT_BANDS)\n","        if arr is None or arr.shape[0] < 2:\n","            print(f\"âš ï¸ Skipping {it['path']} â€” unreadable or missing bands.\")\n","            continue\n","\n","        # Expect at least VV & VH in dB in the first two positions based on SELECT_BANDS\n","        if arr.shape[0] < 2:\n","            print(f\"Skipping {it['path']}: Less than 2 bands read.\")\n","            continue\n","\n","        vv_db = arr[0]; vh_db = arr[1]\n","        result = compute_proxies(vv_db, vh_db)\n","        if result[0] is None:\n","            print(f\"âš ï¸ Skipping {it['path']} â€” no valid pixels.\")\n","            continue\n","\n","        metrics, rvi, water_mask, bare_mask = result\n","        rec = dict(\n","            aoi=it[\"aoi\"], year=it[\"year\"], quart=it[\"quart\"], source=it[\"source\"],\n","            t_index=t_index(it[\"year\"], it[\"quart\"]),\n","            path=it[\"path\"], **metrics\n","        )\n","        records.append(rec)\n","        by_aoi_time[(it[\"aoi\"], rec[\"t_index\"])] = rec\n","    except Exception as e:\n","        # Catch any other unexpected errors during the rest of the processing loop\n","        print(f\"âŒ Error processing {it['path']}: {e}\")\n","        continue\n","\n","\n","if not records:\n","    raise ValueError(\"No valid raster files processed. Please check input paths and file formats.\")\n","\n","# Save CSV to Drive\n","os.makedirs(\"/content/out\", exist_ok=True) # Keep local staging dir if needed\n","os.makedirs(OUT_DRIVE_DIR, exist_ok=True) # Ensure Drive output directory exists\n","csv_path = \"/content/out/sar_metrics.csv\"\n","with open(csv_path, \"w\", newline=\"\") as f:\n","    w = csv.DictWriter(f, fieldnames=list(records[0].keys()))\n","    w.writeheader(); w.writerows(records)\n","\n","# Replace gcs_upload with save_to_drive\n","def save_to_drive(local_path, filename=None):\n","    if not filename:\n","        filename = os.path.basename(local_path)\n","    dest = os.path.join(OUT_DRIVE_DIR, filename)\n","    shutil.copy(local_path, dest)\n","    print(f\"âœ… Saved to Drive: {dest}\")\n","\n","save_to_drive(csv_path, \"sar_metrics.csv\")\n","print(\"âœ… Metrics CSV saved to Drive.\")\n","\n","# ============================================================\n","# 5) Recovery analytics + narrative per AOI  (robust version)\n","# ============================================================\n","def aois():\n","    return sorted(set(r[\"aoi\"] for r in records))\n","\n","def rows_for_aoi(aoi):\n","    return sorted([r for r in records if r[\"aoi\"] == aoi], key=lambda d: d[\"t_index\"])\n","\n","def control_rows(rows):\n","    return [r for r in rows if in_control(r[\"year\"], r[\"quart\"])]\n","\n","def period_rows(rows, start_year, end_year):\n","    return [r for r in rows if start_year <= r[\"year\"] <= end_year]\n","\n","def latest_in_year(rows, year):\n","    cands = [r for r in rows if r[\"year\"] == year]\n","    return sorted(cands, key=lambda d: d[\"t_index\"])[-1] if cands else None\n","\n","def compute_recovery_series(rows, key, decline_start=2018, decline_end=2022, final_year=2025):\n","    \"\"\"Compute recovery metrics robustly (ignores NaN).\"\"\"\n","    vals_ctrl = [r[key] for r in control_rows(rows) if np.isfinite(r.get(key, np.nan))]\n","    vals_decl = [r[key] for r in period_rows(rows, decline_start, decline_end) if np.isfinite(r.get(key, np.nan))]\n","    last_r = latest_in_year(rows, final_year)\n","\n","    baseline = np.nanmean(vals_ctrl) if vals_ctrl else np.nan\n","    worst = np.nanmin(vals_decl) if vals_decl else np.nan\n","    final_val = float(last_r[key]) if last_r and np.isfinite(last_r.get(key, np.nan)) else np.nan\n","\n","    denom = baseline - worst\n","    if not np.isfinite(baseline) or not np.isfinite(worst) or not np.isfinite(final_val) or abs(denom) < 1e-9:\n","        rec_pct = np.nan\n","    else:\n","        rec_pct = np.clip((final_val - worst) / denom * 100.0, -200, 200)\n","\n","    return dict(baseline=baseline, worst=worst, final=final_val, recovery_pct=rec_pct)\n","\n","summaries = []\n","for a in aois():\n","    rows = rows_for_aoi(a)\n","    if not rows:\n","        continue\n","\n","    rvi = compute_recovery_series(rows, \"rvi_mean\")\n","    wat = compute_recovery_series(rows, \"water_frac\")\n","    bare = compute_recovery_series(rows, \"bare_frac\")\n","\n","    # Skip AOIs completely empty\n","    if all(np.isnan(x[\"baseline\"]) for x in [rvi, wat, bare]):\n","        print(f\"âš ï¸ AOI {a} has no valid data â€” skipped.\")\n","        continue\n","\n","    summaries.append(dict(\n","        aoi=a,\n","        rvi_baseline=rvi[\"baseline\"], rvi_worst=rvi[\"worst\"], rvi_2025=rvi[\"final\"], rvi_recovery_pct=rvi[\"recovery_pct\"],\n","        water_baseline=wat[\"baseline\"], water_worst=wat[\"worst\"], water_2025=wat[\"final\"], water_recovery_pct=wat[\"recovery_pct\"],\n","        bare_baseline=bare[\"baseline\"], bare_worst=bare[\"worst\"], bare_2025=bare[\"final\"], bare_recovery_pct=bare[\"recovery_pct\"]\n","    ))\n","\n","# --- Always write a CSV, even if some AOIs missing ---\n","os.makedirs(\"/content/out\", exist_ok=True)\n","sum_path = \"/content/out/recovery_summaries.csv\"\n","if summaries:\n","    with open(sum_path, \"w\", newline=\"\") as f:\n","        w = csv.DictWriter(f, fieldnames=list(summaries[0].keys()))\n","        w.writeheader(); w.writerows(summaries)\n","    save_to_drive(sum_path, \"recovery_summaries.csv\")\n","    print(f\"âœ… Recovery summaries saved to Drive ({len(summaries)} AOIs).\")\n","else:\n","    # Create empty CSV with headers for consistency\n","    with open(sum_path, \"w\", newline=\"\") as f:\n","        f.write(\"aoi,rvi_baseline,rvi_worst,rvi_2025,rvi_recovery_pct,water_baseline,water_worst,water_2025,water_recovery_pct,bare_baseline,bare_worst,bare_2025,bare_recovery_pct\\n\")\n","    save_to_drive(sum_path, \"recovery_summaries_empty.csv\")\n","    print(\"âš ï¸ No valid AOIs for recovery summaries â€” empty CSV created.\")\n","\n","\n","# ============================================================\n","# 6) Plots per AOI (timelines for RVI, water, bare)\n","# ============================================================\n","if MAKE_PLOTS:\n","    os.makedirs(\"/content/out/plots\", exist_ok=True)\n","    for a in aois():\n","        rows = rows_for_aoi(a)\n","        rows = [r for r in rows if r[\"aoi\"] in aois() and r[\"t_index\"] in by_aoi_time.keys()] # Filter for successfully processed records\n","        if not rows: continue # Skip AOI if no records were processed\n","\n","        rows = sorted(rows, key=lambda d:d[\"t_index\"])\n","        xs = [f\"{r['year']}_{r['quart']}\" for r in rows]\n","        rvi = [r[\"rvi_mean\"] for r in rows]\n","        wat = [r[\"water_frac\"] for r in rows]\n","        bar = [r[\"bare_frac\"] for r in rows]\n","        col = [\"#d62728\" if r[\"source\"]==\"hotspot\" else \"#1f77b4\" for r in rows]\n","\n","        fig, ax = plt.subplots(3, 1, figsize=(12,8), sharex=True)\n","        ax[0].plot(xs, rvi, marker=\"o\"); ax[0].set_ylabel(\"RVI (veg/biomass)\")\n","        ax[1].plot(xs, wat, marker=\"o\"); ax[1].set_ylabel(\"Water fraction\")\n","        ax[2].plot(xs, bar, marker=\"o\"); ax[2].set_ylabel(\"Bare/infra fraction\")\n","        for a_i in ax:\n","            a_i.grid(True, alpha=0.3)\n","        plt.xticks(rotation=60)\n","        plt.suptitle(f\"AOI {a} â€” baseline (blue) vs hotspots (red)\")\n","        plt.tight_layout(rect=[0,0,1,0.98])\n","\n","        png = f\"/content/out/plots/ao{a}_timeseries.png\"\n","        plt.savefig(png, dpi=170); plt.close()\n","        # Replace gcs_upload with save_to_drive\n","        save_to_drive(png)\n","\n","\n","# ============================================================\n","# 7) Optional GIF per AOI (RVI map through time, low-res)\n","# ============================================================\n","def make_rvi_frame(vv_db, vh_db, ds=GIF_DOWNSAMPLE):\n","    vv_lin = db_to_lin(vv_db); vh_lin = db_to_lin(vh_db)\n","    rvi = 4.0 * vh_lin / np.maximum(vv_lin + vh_lin, 1e-6)\n","    rvi = np.clip(rvi, 0, 1)\n","    if ds and ds>1:\n","        H,W = rvi.shape\n","        rvi = rvi[:H - H%ds, :W - W%ds]   # crop\n","        rvi = rvi.reshape(rvi.shape[0]//ds, ds, rvi.shape[1]//ds, ds).mean(axis=(1,3))\n","    # stretch to 0..255\n","    lo, hi = np.nanpercentile(rvi, 2), np.nanpercentile(rvi, 98)\n","    v = np.clip((rvi - lo) / max(1e-6, hi-lo), 0, 1)\n","    return (v*255).astype(np.uint8)\n","\n","if MAKE_GIFS:\n","    os.makedirs(\"/content/out/gifs\", exist_ok=True)\n","    for a in aois():\n","        rows = rows_for_aoi(a)\n","        rows = [r for r in rows if r[\"aoi\"] in aois() and r[\"t_index\"] in by_aoi_time.keys()] # Filter for successfully processed records\n","        if not rows: continue # Skip AOI if no records were processed\n","\n","        frames = []; labels=[]\n","        for r in sorted(rows, key=lambda d:d[\"t_index\"]):\n","            try:\n","                arr, _, _ = read_selected_bands(r[\"path\"], SELECT_BANDS)\n","                if arr is None: continue # Skip if reading failed\n","\n","                # Ensure we have at least two bands for VV and VH\n","                if arr.shape[0] < 2:\n","                    print(f\"Skipping GIF frame for {r['path']}: Less than 2 bands available.\")\n","                    continue\n","                vv_db, vh_db = arr[0], arr[1]\n","                frames.append(make_rvi_frame(vv_db, vh_db, ds=GIF_DOWNSAMPLE))\n","                labels.append(f\"{r['year']}_{r['quart']}\")\n","            except Exception as e:\n","                 print(f\"Unexpected error creating GIF frame for {r['path']}: {e}\") # More specific error message\n","                 continue # Skip this frame but continue with others\n","\n","        if frames:\n","            gif_local = f\"/content/out/gifs/ao{a}_rvi.gif\"\n","            imageio.mimsave(gif_local, frames, duration=0.8)\n","            # Replace gcs_upload with save_to_drive\n","            save_to_drive(gif_local)\n","            print(f\"ðŸŽžï¸ GIF saved for AOI {a}\")\n","\n","# ============================================================\n","# 8) Autoencoder Model\n","# ============================================================\n","\n","# Define IN_CHANNELS based on SELECT_BANDS\n","IN_CHANNELS = len(SELECT_BANDS)\n","\n","# Simple Conv-ReLU-BatchNorm block\n","def conv_block(in_c, out_c):\n","    return nn.Sequential(\n","        nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n","        nn.ReLU(inplace=True),\n","        nn.BatchNorm2d(out_c)\n","    )\n","\n","# Contracting Path (Encoder)\n","def encoder_block(in_c, out_c):\n","    return nn.Sequential(\n","        conv_block(in_c, out_c),\n","        conv_block(out_c, out_c),\n","        nn.MaxPool2d(2)\n","    )\n","\n","# Expanding Path (Decoder)\n","def decoder_block(in_c, out_c):\n","    return nn.Sequential(\n","        nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2),\n","        conv_block(out_c, out_c),\n","        conv_block(out_c, out_c)\n","    )\n","\n","class UNetAutoencoder(nn.Module):\n","    def __init__(self, in_channels=IN_CHANNELS, base_channels=BASE_CHANNELS):\n","        super().__init__()\n","        self.enc1 = encoder_block(in_channels, base_channels)\n","        self.enc2 = encoder_block(base_channels, base_channels*2)\n","        self.enc3 = encoder_block(base_channels*2, base_channels*4)\n","        self.enc4 = encoder_block(base_channels*4, base_channels*8)\n","\n","        self.bottleneck = conv_block(base_channels*8, base_channels*16)\n","\n","        self.dec4 = decoder_block(base_channels*16, base_channels*8)\n","        self.dec3 = decoder_block(base_channels*8, base_channels*4)\n","        self.dec2 = decoder_block(base_channels*4, base_channels*2)\n","        self.dec1 = decoder_block(base_channels*2, base_channels)\n","\n","        self.out_conv = nn.Conv2d(base_channels, in_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(enc1)\n","        enc3 = self.enc3(enc2)\n","        enc4 = self.enc4(enc3)\n","\n","        bottleneck = self.bottleneck(enc4)\n","\n","        dec4 = self.dec4(bottleneck)\n","        dec3 = self.dec3(dec4 + enc3) # Skip connection\n","        dec2 = self.dec2(dec3 + enc2) # Skip connection\n","        dec1 = self.dec1(dec2 + enc1) # Skip connection\n","\n","        return self.out_conv(dec1)\n","\n","# Instantiate model\n","model = UNetAutoencoder(in_channels=IN_CHANNELS, base_channels=BASE_CHANNELS)"]},{"cell_type":"code","source":["# Unmount if drive got stuck before\n","from google.colab import drive\n","!fusermount -u /content/drive || true\n","\n","# Mount again cleanly\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RkImJlfA0_z","executionInfo":{"status":"ok","timestamp":1759678523462,"user_tz":360,"elapsed":2334,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"31094ae2-22e1-4c9e-c326-667d76a2546e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import rasterio\n","import numpy as np\n","import csv, os, requests\n","from io import BytesIO\n","from google.colab import drive\n","\n","\n","BUCKET = \"nasa_sar_spacetron\"\n","OUT_DIR = \"/content/drive/MyDrive/SAR_Results\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# === your raster paths from GCS ===\n","raster_paths = [\n","    \"CLEAN/Interest_clean/AOI_1_2024_Q1.tif\",\n","    \"CLEAN/Interest_clean/AOI_2_2023_Q2.tif\",\n","    \"CLEAN/Interest_clean/AOI_3_2022_Q4.tif\",\n","    \"CLEAN/Interest_clean/AOI_4_2025_Q1.tif\",\n","]\n","\n","records = []\n","for path in raster_paths:\n","    url = f\"https://storage.googleapis.com/{BUCKET}/{path}\"\n","    print(f\"\\nðŸ“‚ Processing {url}\")\n","    try:\n","        resp = requests.get(url, stream=True)\n","        resp.raise_for_status()\n","        with rasterio.open(BytesIO(resp.content)) as src:\n","            arr = src.read()[:3]     # first 3 bands â†’ VV, VH, angle\n","            if np.all(np.isnan(arr)) or np.nanmean(arr) == 0:\n","                print(\"âš ï¸ Skipping (empty or no signal)\")\n","                continue\n","\n","            vv, vh, ang = arr[0], arr[1], arr[2]\n","            rec = {\n","                \"file\": os.path.basename(path),\n","                \"aoi\": path.split(\"_\")[1],\n","                \"year\": path.split(\"_\")[2],\n","                \"quarter\": path.split(\"_\")[3].split(\".\")[0],\n","                \"vv_mean\": np.nanmean(vv),\n","                \"vv_std\": np.nanstd(vv),\n","                \"vh_mean\": np.nanmean(vh),\n","                \"vh_std\": np.nanstd(vh),\n","                \"angle_mean\": np.nanmean(ang),\n","                \"angle_std\": np.nanstd(ang),\n","                \"valid_ratio\": np.sum(~np.isnan(arr)) / arr.size\n","            }\n","            records.append(rec)\n","            print(f\"âœ… Added metrics for {rec['file']}\")\n","\n","    except Exception as e:\n","        print(f\"âŒ Error reading {path}: {e}\")\n","\n","# === Save metrics to Drive ===\n","if records:\n","    out_csv = os.path.join(OUT_DIR, \"sar_metrics_valid.csv\")\n","    with open(out_csv, \"w\", newline=\"\") as f:\n","        writer = csv.DictWriter(f, fieldnames=records[0].keys())\n","        writer.writeheader(); writer.writerows(records)\n","    print(f\"\\nâœ… CSV saved to Drive: {out_csv}\")\n","else:\n","    print(\"âŒ No valid rasters processed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSGM9BrG-jPt","executionInfo":{"status":"ok","timestamp":1759678261298,"user_tz":360,"elapsed":2171,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"9c1da749-eb64-406a-8b16-7d398189d977"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“‚ Processing https://storage.googleapis.com/nasa_sar_spacetron/CLEAN/Interest_clean/AOI_1_2024_Q1.tif\n","âœ… Added metrics for AOI_1_2024_Q1.tif\n","\n","ðŸ“‚ Processing https://storage.googleapis.com/nasa_sar_spacetron/CLEAN/Interest_clean/AOI_2_2023_Q2.tif\n","âœ… Added metrics for AOI_2_2023_Q2.tif\n","\n","ðŸ“‚ Processing https://storage.googleapis.com/nasa_sar_spacetron/CLEAN/Interest_clean/AOI_3_2022_Q4.tif\n","âœ… Added metrics for AOI_3_2022_Q4.tif\n","\n","ðŸ“‚ Processing https://storage.googleapis.com/nasa_sar_spacetron/CLEAN/Interest_clean/AOI_4_2025_Q1.tif\n","âœ… Added metrics for AOI_4_2025_Q1.tif\n","\n","âœ… CSV saved to Drive: /content/drive/MyDrive/SAR_Results/sar_metrics_valid.csv\n"]}]},{"cell_type":"code","source":["!find /content -type f -name \"*.csv\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etaRWOs5ABTZ","executionInfo":{"status":"ok","timestamp":1759678308263,"user_tz":360,"elapsed":745,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"33d70c03-9c04-4f89-e42d-f8000957cde0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SAR_Exports/asf-opera-displacement-2025-10-04_10-26-41.csv\n","/content/drive/MyDrive/SAR_Exports/sar_exports_manifest.csv\n","/content/drive/MyDrive/SAR_Results/sar_metrics_valid.csv\n","/content/out/sar_metrics.csv\n","/content/out/recovery_summaries.csv\n","/content/sample_data/california_housing_train.csv\n","/content/sample_data/mnist_test.csv\n","/content/sample_data/mnist_train_small.csv\n","/content/sample_data/california_housing_test.csv\n"]}]},{"cell_type":"code","source":["import shutil, os\n","\n","src = \"/content/out/sar_metrics.csv\"\n","dst = \"/content/drive/MyDrive/SAR_Results/sar_metrics_valid.csv\"\n","\n","os.makedirs(\"/content/drive/MyDrive/SAR_Results\", exist_ok=True)\n","if os.path.exists(src):\n","    shutil.copy(src, dst)\n","    print(f\"âœ… Copied to Drive: {dst}\")\n","else:\n","    print(f\"âš ï¸ Source not found: {src}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTsrrLs4AM4q","executionInfo":{"status":"ok","timestamp":1759678355314,"user_tz":360,"elapsed":46,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"3befa09f-c131-4558-cf1a-0d2751ab0ecb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Copied to Drive: /content/drive/MyDrive/SAR_Results/sar_metrics_valid.csv\n"]}]},{"cell_type":"code","source":["!rm -rf /content/drive  # ðŸ§¹ Delete the old mount folder\n"],"metadata":{"id":"-lIgbM_w_iXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfC1_0si_lmF","executionInfo":{"status":"ok","timestamp":1759678201404,"user_tz":360,"elapsed":7260,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"bb507cc5-dd67-4315-c410-ea3d673152d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import shutil, os\n","\n","src = \"/content/sar_metrics_valid.csv\"\n","dst = \"/content/drive/MyDrive/SAR_Results/sar_metrics_valid.csv\"\n","\n","os.makedirs(\"/content/drive/MyDrive/SAR_Results\", exist_ok=True)\n","if os.path.exists(src):\n","    shutil.copy(src, dst)\n","    print(f\"âœ… CSV copied to Drive: {dst}\")\n","else:\n","    print(\"âš ï¸ No CSV found at\", src)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeNN9qD0_sdN","executionInfo":{"status":"ok","timestamp":1759678222371,"user_tz":360,"elapsed":238,"user":{"displayName":"Alonso Lopez","userId":"09479288159718956014"}},"outputId":"7568704f-3917-474a-b8b5-8768241c67c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âš ï¸ No CSV found at /content/sar_metrics_valid.csv\n"]}]}]}