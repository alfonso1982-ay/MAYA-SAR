{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uMjB_HQQ1Kno"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "‚úÖ Base config loaded from GitHub.\n",
      "‚úÖ Configuration merged successfully.\n",
      "‚Üí Project: nasa-space-apps-473722\n",
      "‚Üí Bucket: nasa_sar_spacetron\n",
      "‚Üí AOI: https://drive.google.com/uc?export=download&id=1oPVRvGny1y-pDE-5G-ayTUpSGHw0Rlh-\n",
      "‚Üí Years: 2020‚Äì2025\n",
      "‚Üí Output folders: {'exports': 'SAR_Exports', 'clean': 'CLEAN/SAR_Exports', 'mosaics': 'CLEAN/SAR_Mosaics', 'models': 'models', 'manifest': 'manifest'}\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'manifest'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# 3Ô∏è‚É£ Logging Setup\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     69\u001b[39m LOG_PATH = CONFIG[\u001b[33m\"\u001b[39m\u001b[33morchestrator\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mpipeline_log\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLOG_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_stage\u001b[39m(stage, status, duration_min, message=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     73\u001b[39m     row = {\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: datetime.datetime.utcnow().isoformat(),\n\u001b[32m     75\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m: stage,\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m: message\n\u001b[32m     79\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'manifest'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üöÄ FULL PIPELINE ORCHESTRATOR (Dynamic Config Merge)\n",
    "# ============================================================\n",
    "\n",
    "!pip install papermill requests -q\n",
    "import papermill as pm\n",
    "import json, requests, time, csv, os, datetime\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Load base config from GitHub (for SAR extractor)\n",
    "# ============================================================\n",
    "CONFIG_URL = \"https://raw.githubusercontent.com/JuanoS12/Space-Apps/main/scripts/automate/config.json\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(CONFIG_URL)\n",
    "    response.raise_for_status()\n",
    "    BASE_CONFIG = response.json()\n",
    "    print(f\"‚úÖ Base config loaded from GitHub.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not fetch remote config ({e}). Falling back to local 'config.json'\")\n",
    "    with open(\"config.json\") as f:\n",
    "        BASE_CONFIG = json.load(f)\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Extend config with orchestrator-specific parameters\n",
    "# ============================================================\n",
    "\n",
    "EXTRA_CONFIG = {\n",
    "    \"folders\": {\n",
    "        \"exports\": \"SAR_Exports\",\n",
    "        \"clean\": \"CLEAN/SAR_Exports\",\n",
    "        \"mosaics\": \"CLEAN/SAR_Mosaics\",\n",
    "        \"models\": \"models\",\n",
    "        \"manifest\": \"manifest\"\n",
    "    },\n",
    "    \"cleaning\": {\n",
    "        \"skip_existing\": True,\n",
    "        \"dtype\": \"float32\"\n",
    "    },\n",
    "    \"mosaic\": {\n",
    "        \"expected_aois\": 12,\n",
    "        \"parallel_downloads\": 4\n",
    "    },\n",
    "    \"ml\": {\n",
    "        \"enable_training\": False,\n",
    "        \"model_type\": \"unet_resnet34\",\n",
    "        \"model_path\": \"models/unet34_latest.pth\"\n",
    "    },\n",
    "    \"orchestrator\": {\n",
    "        \"pipeline_log\": \"manifest/pipeline_log.csv\",\n",
    "        \"stop_on_error\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Merge both configurations\n",
    "CONFIG = {**BASE_CONFIG, **EXTRA_CONFIG}\n",
    "\n",
    "print(\"‚úÖ Configuration merged successfully.\")\n",
    "print(f\"‚Üí Project: {CONFIG['project_id']}\")\n",
    "print(f\"‚Üí Bucket: {CONFIG['bucket']}\")\n",
    "print(f\"‚Üí AOI: {CONFIG['aoi_kmz']}\")\n",
    "print(f\"‚Üí Years: {CONFIG['start_year']}‚Äì{CONFIG['end_year']}\")\n",
    "print(f\"‚Üí Output folders: {CONFIG['folders']}\")\n",
    "print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ Logging Setup\n",
    "# ============================================================\n",
    "LOG_PATH = CONFIG[\"orchestrator\"][\"pipeline_log\"]\n",
    "os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)\n",
    "\n",
    "def log_stage(stage, status, duration_min, message=\"\"):\n",
    "    row = {\n",
    "        \"timestamp\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"stage\": stage,\n",
    "        \"status\": status,\n",
    "        \"duration_min\": round(duration_min, 2),\n",
    "        \"message\": message\n",
    "    }\n",
    "    write_header = not os.path.exists(LOG_PATH)\n",
    "    with open(LOG_PATH, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ Define pipeline sequence\n",
    "# ============================================================\n",
    "PIPELINE_STEPS = [\n",
    "    (\"sar_time_lapse.ipynb\", \"01_extract_output.ipynb\"),\n",
    "    (\"Limpia.ipynb\", \"02_clean_output.ipynb\"),\n",
    "    (\"mosaic.ipynb\", \"03_mosaic_output.ipynb\")\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ Execute pipeline\n",
    "# ============================================================\n",
    "start_total = time.time()\n",
    "for idx, (input_nb, output_nb) in enumerate(PIPELINE_STEPS, start=1):\n",
    "    print(f\"\\nüöÄ Step {idx}/{len(PIPELINE_STEPS)} ‚Üí Running {input_nb} ...\")\n",
    "    stage_start = time.time()\n",
    "    try:\n",
    "        pm.execute_notebook(input_nb, output_nb, parameters=dict(CONFIG=CONFIG))\n",
    "        duration = (time.time() - stage_start) / 60\n",
    "        print(f\"‚úÖ {input_nb} completed in {duration:.2f} min.\")\n",
    "        log_stage(input_nb, \"success\", duration)\n",
    "    except Exception as e:\n",
    "        duration = (time.time() - stage_start) / 60\n",
    "        print(f\"‚ùå Error in {input_nb}: {e}\")\n",
    "        log_stage(input_nb, \"failed\", duration, str(e))\n",
    "        if CONFIG[\"orchestrator\"][\"stop_on_error\"]:\n",
    "            break\n",
    "\n",
    "total_duration = (time.time() - start_total) / 60\n",
    "print(\"\\nüéØ Full pipeline completed.\")\n",
    "print(f\"‚è±Ô∏è Total runtime: {total_duration:.2f} min\")\n",
    "log_stage(\"full_pipeline\", \"completed\", total_duration)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnMqMiGmYIfQz81WkvIkrh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
